{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210760b0",
   "metadata": {},
   "source": [
    "Name: Nguyễn Lâm Vĩnh Gia - ID: 2052074\n",
    "\n",
    "# NAIVE BAYES CLASSIFIER\n",
    "\n",
    "* Seperate data by the type of flower "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d7b42f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: [array([5.1, 3.5, 1.4, 0.2]), array([4.9, 3. , 1.4, 0.2]), array([4.7, 3.2, 1.3, 0.2]), array([4.6, 3.1, 1.5, 0.2]), array([5. , 3.6, 1.4, 0.2]), array([5.4, 3.9, 1.7, 0.4]), array([4.6, 3.4, 1.4, 0.3]), array([5. , 3.4, 1.5, 0.2]), array([4.4, 2.9, 1.4, 0.2]), array([4.9, 3.1, 1.5, 0.1]), array([5.4, 3.7, 1.5, 0.2]), array([4.8, 3.4, 1.6, 0.2]), array([4.8, 3. , 1.4, 0.1]), array([4.3, 3. , 1.1, 0.1]), array([5.8, 4. , 1.2, 0.2]), array([5.7, 4.4, 1.5, 0.4]), array([5.4, 3.9, 1.3, 0.4]), array([5.1, 3.5, 1.4, 0.3]), array([5.7, 3.8, 1.7, 0.3]), array([5.1, 3.8, 1.5, 0.3]), array([5.4, 3.4, 1.7, 0.2]), array([5.1, 3.7, 1.5, 0.4]), array([4.6, 3.6, 1. , 0.2]), array([5.1, 3.3, 1.7, 0.5]), array([4.8, 3.4, 1.9, 0.2]), array([5. , 3. , 1.6, 0.2]), array([5. , 3.4, 1.6, 0.4]), array([5.2, 3.5, 1.5, 0.2]), array([5.2, 3.4, 1.4, 0.2]), array([4.7, 3.2, 1.6, 0.2]), array([4.8, 3.1, 1.6, 0.2]), array([5.4, 3.4, 1.5, 0.4]), array([5.2, 4.1, 1.5, 0.1]), array([5.5, 4.2, 1.4, 0.2]), array([4.9, 3.1, 1.5, 0.2]), array([5. , 3.2, 1.2, 0.2]), array([5.5, 3.5, 1.3, 0.2]), array([4.9, 3.6, 1.4, 0.1]), array([4.4, 3. , 1.3, 0.2]), array([5.1, 3.4, 1.5, 0.2]), array([5. , 3.5, 1.3, 0.3]), array([4.5, 2.3, 1.3, 0.3]), array([4.4, 3.2, 1.3, 0.2]), array([5. , 3.5, 1.6, 0.6]), array([5.1, 3.8, 1.9, 0.4]), array([4.8, 3. , 1.4, 0.3]), array([5.1, 3.8, 1.6, 0.2]), array([4.6, 3.2, 1.4, 0.2]), array([5.3, 3.7, 1.5, 0.2]), array([5. , 3.3, 1.4, 0.2])], 1.0: [array([7. , 3.2, 4.7, 1.4]), array([6.4, 3.2, 4.5, 1.5]), array([6.9, 3.1, 4.9, 1.5]), array([5.5, 2.3, 4. , 1.3]), array([6.5, 2.8, 4.6, 1.5]), array([5.7, 2.8, 4.5, 1.3]), array([6.3, 3.3, 4.7, 1.6]), array([4.9, 2.4, 3.3, 1. ]), array([6.6, 2.9, 4.6, 1.3]), array([5.2, 2.7, 3.9, 1.4]), array([5. , 2. , 3.5, 1. ]), array([5.9, 3. , 4.2, 1.5]), array([6. , 2.2, 4. , 1. ]), array([6.1, 2.9, 4.7, 1.4]), array([5.6, 2.9, 3.6, 1.3]), array([6.7, 3.1, 4.4, 1.4]), array([5.6, 3. , 4.5, 1.5]), array([5.8, 2.7, 4.1, 1. ]), array([6.2, 2.2, 4.5, 1.5]), array([5.6, 2.5, 3.9, 1.1]), array([5.9, 3.2, 4.8, 1.8]), array([6.1, 2.8, 4. , 1.3]), array([6.3, 2.5, 4.9, 1.5]), array([6.1, 2.8, 4.7, 1.2]), array([6.4, 2.9, 4.3, 1.3]), array([6.6, 3. , 4.4, 1.4]), array([6.8, 2.8, 4.8, 1.4]), array([6.7, 3. , 5. , 1.7]), array([6. , 2.9, 4.5, 1.5]), array([5.7, 2.6, 3.5, 1. ]), array([5.5, 2.4, 3.8, 1.1]), array([5.5, 2.4, 3.7, 1. ]), array([5.8, 2.7, 3.9, 1.2]), array([6. , 2.7, 5.1, 1.6]), array([5.4, 3. , 4.5, 1.5]), array([6. , 3.4, 4.5, 1.6]), array([6.7, 3.1, 4.7, 1.5]), array([6.3, 2.3, 4.4, 1.3]), array([5.6, 3. , 4.1, 1.3]), array([5.5, 2.5, 4. , 1.3]), array([5.5, 2.6, 4.4, 1.2]), array([6.1, 3. , 4.6, 1.4]), array([5.8, 2.6, 4. , 1.2]), array([5. , 2.3, 3.3, 1. ]), array([5.6, 2.7, 4.2, 1.3]), array([5.7, 3. , 4.2, 1.2]), array([5.7, 2.9, 4.2, 1.3]), array([6.2, 2.9, 4.3, 1.3]), array([5.1, 2.5, 3. , 1.1]), array([5.7, 2.8, 4.1, 1.3])], 2.0: [array([6.3, 3.3, 6. , 2.5]), array([5.8, 2.7, 5.1, 1.9]), array([7.1, 3. , 5.9, 2.1]), array([6.3, 2.9, 5.6, 1.8]), array([6.5, 3. , 5.8, 2.2]), array([7.6, 3. , 6.6, 2.1]), array([4.9, 2.5, 4.5, 1.7]), array([7.3, 2.9, 6.3, 1.8]), array([6.7, 2.5, 5.8, 1.8]), array([7.2, 3.6, 6.1, 2.5]), array([6.5, 3.2, 5.1, 2. ]), array([6.4, 2.7, 5.3, 1.9]), array([6.8, 3. , 5.5, 2.1]), array([5.7, 2.5, 5. , 2. ]), array([5.8, 2.8, 5.1, 2.4]), array([6.4, 3.2, 5.3, 2.3]), array([6.5, 3. , 5.5, 1.8]), array([7.7, 3.8, 6.7, 2.2]), array([7.7, 2.6, 6.9, 2.3]), array([6. , 2.2, 5. , 1.5]), array([6.9, 3.2, 5.7, 2.3]), array([5.6, 2.8, 4.9, 2. ]), array([7.7, 2.8, 6.7, 2. ]), array([6.3, 2.7, 4.9, 1.8]), array([6.7, 3.3, 5.7, 2.1]), array([7.2, 3.2, 6. , 1.8]), array([6.2, 2.8, 4.8, 1.8]), array([6.1, 3. , 4.9, 1.8]), array([6.4, 2.8, 5.6, 2.1]), array([7.2, 3. , 5.8, 1.6]), array([7.4, 2.8, 6.1, 1.9]), array([7.9, 3.8, 6.4, 2. ]), array([6.4, 2.8, 5.6, 2.2]), array([6.3, 2.8, 5.1, 1.5]), array([6.1, 2.6, 5.6, 1.4]), array([7.7, 3. , 6.1, 2.3]), array([6.3, 3.4, 5.6, 2.4]), array([6.4, 3.1, 5.5, 1.8]), array([6. , 3. , 4.8, 1.8]), array([6.9, 3.1, 5.4, 2.1]), array([6.7, 3.1, 5.6, 2.4]), array([6.9, 3.1, 5.1, 2.3]), array([5.8, 2.7, 5.1, 1.9]), array([6.8, 3.2, 5.9, 2.3]), array([6.7, 3.3, 5.7, 2.5]), array([6.7, 3. , 5.2, 2.3]), array([6.3, 2.5, 5. , 1.9]), array([6.5, 3. , 5.2, 2. ]), array([6.2, 3.4, 5.4, 2.3]), array([5.9, 3. , 5.1, 1.8])]}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, pi, exp\n",
    "\n",
    "# Function to load the CSV file and convert it to numpy array for further execution\n",
    "def loadCSV(file_path):\n",
    "    df = pd.read_csv(file_path, encoding = 'utf-8')\n",
    "    df['variety'] = pd.Categorical(df['variety']).codes\n",
    "    data_frame = df.to_numpy()\n",
    "    return data_frame\n",
    "\n",
    "# Function to seperate data by class\n",
    "def seperateClass(data_frame):\n",
    "    seperate_class = dict()\n",
    "    for i in range(len(data_frame)):\n",
    "        data_row = data_frame[i]\n",
    "        class_name = data_row[-1]\n",
    "        if class_name not in seperate_class:\n",
    "            seperate_class[class_name] = list()\n",
    "        seperate_class[class_name].append(data_row[:(len(data_row) - 1)])\n",
    "    return seperate_class\n",
    "\n",
    "file_path = r\"C:\\Studying Documents\\Artificial intelligient\\Exercise\\Dataset\\Iris.csv\"\n",
    "data_frame = loadCSV(file_path)\n",
    "sep_class = seperateClass(data_frame)\n",
    "print(sep_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208af10",
   "metadata": {},
   "source": [
    "* Summarize the dataset to get the mean, standard deviation and length of each data column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58be7354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5.843333333333335, 0.8280661279778629, 150), (3.057333333333334, 0.435866284936698, 150), (3.7580000000000027, 1.7652982332594667, 150), (1.199333333333334, 0.7622376689603465, 150)]\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the mean of the data list\n",
    "def mean(data_list):\n",
    "    return sum(data_list) / float(len(data_list))\n",
    "\n",
    "# Function to calculate the standard deviation of the data list\n",
    "def stdev(data_list):\n",
    "    data_mean = mean(data_list)\n",
    "    variance = sum((x - data_mean) ** 2 for x in data_list) / float(len(data_list) - 1)\n",
    "    return sqrt(variance)\n",
    "\n",
    "# Function to summarize the dataset\n",
    "def dataSummarize(data_frame):\n",
    "    summary = [(mean(column), stdev(column), len(column)) for column in zip(*data_frame)]\n",
    "    del(summary[-1])\n",
    "    return summary\n",
    "\n",
    "data_summary = dataSummarize(data_frame)\n",
    "print(data_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d82f3d",
   "metadata": {},
   "source": [
    "* Summarize the data of each type of flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faf9af3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: [(5.005999999999999, 0.3524896872134512, 50), (3.428000000000001, 0.3790643690962886, 50), (1.4620000000000002, 0.1736639964801841, 50)], 1.0: [(5.936, 0.5161711470638635, 50), (2.7700000000000005, 0.3137983233784114, 50), (4.26, 0.46991097723995806, 50)], 2.0: [(6.587999999999998, 0.635879593274432, 50), (2.9739999999999998, 0.3224966381726376, 50), (5.552, 0.5518946956639835, 50)]}\n"
     ]
    }
   ],
   "source": [
    "def summarize_byClass(data_frame):\n",
    "    sep_class = seperateClass(data_frame)\n",
    "    summary_by_class = dict()\n",
    "    for class_name, data_rows in sep_class.items():\n",
    "        summary_by_class[class_name] = dataSummarize(data_rows)\n",
    "    return summary_by_class\n",
    "\n",
    "lookup_table = summarize_byClass(data_frame)\n",
    "print(lookup_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2dc7f5",
   "metadata": {},
   "source": [
    "* Calculate the normal distribution of each data point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aacac348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19552134698772797\n"
     ]
    }
   ],
   "source": [
    "# Function to calcultae the normal (Gaussian) probability of a data point\n",
    "def gaussianProbability(x, mu, sigma):\n",
    "    return (1 / (sigma * sqrt(2 * pi))) * exp(- (0.5 * ((x - mu) / sigma) ** 2))\n",
    "\n",
    "print(gaussianProbability(3.4, 3.0, 2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de49926",
   "metadata": {},
   "source": [
    "* Calculate the probaility of belonging in a specific class of a data point\n",
    "\n",
    "    We know that the classical naive Bayesian formula is\n",
    "\n",
    "<h1><center>$ p(B|A) = \\frac{p(A|B)p(B)}{p(A)} $</center></h1>\n",
    "\n",
    "which those probabilities share the same denominator. Besides, as we are only interested in the problem of classification, we will simplify the calculation of the probability by eliminate the calculation of the denominator in the Bayes's formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c48563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 0.36858194403030686, 1.0: 6.481447668566026e-11, 2.0: 5.107275067804685e-15}\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the probability of belonging to each class of data of a data point\n",
    "def classProbability(summary, data_point):\n",
    "    data_length = sum([summary[class_][0][2] for class_ in summary])\n",
    "    class_prob = dict()\n",
    "    for class_name, class_summaries in summary.items():\n",
    "        # Get the probability of each class with respect to the whole data frame\n",
    "        class_prob[class_name] = summary[class_name][0][2] / float(data_length)\n",
    "        # Calculate the probability of belonging in each data class of the new data point\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, num = class_summaries[i]\n",
    "            class_prob[class_name] *= gaussianProbability(data_point[i], mean, stdev)\n",
    "    return class_prob\n",
    "\n",
    "# Check the result of a random data point\n",
    "print(classProbability(lookup_table, data_frame[10]))         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2177e2",
   "metadata": {},
   "source": [
    "From the above result, we can easily see that the probability of the data point belonging to the first class is highest, which mean this data belongs to the Setosa flower.\n",
    "\n",
    "## The OOP version of the Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee7d7960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class of the 1st data point is 0.0\n",
      "The class of the 2nd data point is 2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt, pi, exp\n",
    "\n",
    "# Class of Naive Bayes for Iris-alike dataset\n",
    "class NaiveBayes():\n",
    "    # Constructor of the class\n",
    "    def __init__(self, file_path):\n",
    "        self.__file_path = file_path\n",
    "        df = pd.read_csv(self.__file_path, encoding = 'utf-8')\n",
    "        # Convert the class type into integer for easier manipulation\n",
    "        df['variety'] = pd.Categorical(df['variety']).codes\n",
    "        self.data_frame = df.to_numpy()\n",
    "        \n",
    "    # Function to seperate data by class\n",
    "    def seperateClass(self):\n",
    "        seperate_class = dict()\n",
    "        for i in range(len(self.data_frame)):\n",
    "            data_row = self.data_frame[i]\n",
    "            class_name = data_row[-1]\n",
    "            if class_name not in seperate_class:\n",
    "                seperate_class[class_name] = list()\n",
    "            seperate_class[class_name].append(data_row[:(len(data_row) - 1)])\n",
    "        return seperate_class\n",
    "    \n",
    "    # Function to calculate the mean of the data list\n",
    "    def mean(self, data_list):\n",
    "        return sum(data_list) / float(len(data_list))\n",
    "\n",
    "    # Function to calculate the standard deviation of the data list\n",
    "    def stdev(self, data_list):\n",
    "        data_mean = self.mean(data_list)\n",
    "        variance = sum((x - data_mean) ** 2 for x in data_list) / float(len(data_list) - 1)\n",
    "        return sqrt(variance)\n",
    "\n",
    "    # Function to summarize the dataset\n",
    "    def dataSummarize(self, data_frame):\n",
    "        summary = [(self.mean(column), self.stdev(column), len(column)) for column in zip(*data_frame)]\n",
    "        del(summary[-1])\n",
    "        return summary\n",
    "    \n",
    "    # Function to sumarize the data set by the class \n",
    "    def summarize_byClass(self):\n",
    "        sep_class = self.seperateClass()\n",
    "        summary_by_class = dict()\n",
    "        for class_name, data_rows in sep_class.items():\n",
    "            summary_by_class[class_name] = self.dataSummarize(data_rows)\n",
    "        return summary_by_class\n",
    "\n",
    "    # Function to calcultae the normal (Gaussian) probability of a data point\n",
    "    def gaussianProbability(self, x, mu, sigma):\n",
    "        return (1 / (sigma * sqrt(2 * pi))) * exp(- (0.5 * ((x - mu) / sigma) ** 2))\n",
    "    \n",
    "    # Function to calculate the probability of belonging to each class of data of a data point\n",
    "    def classProbability(self, data_point):\n",
    "        summary = self.summarize_byClass()\n",
    "        data_length = sum([summary[class_][0][2] for class_ in summary])\n",
    "        class_prob = dict()\n",
    "        for class_name, class_summaries in summary.items():\n",
    "            # Get the probability of each class with respect to the whole data frame\n",
    "            class_prob[class_name] = summary[class_name][0][2] / float(data_length)\n",
    "            # Calculate the probability of belonging in each data class of the new data point\n",
    "            for i in range(len(class_summaries)):\n",
    "                mean, stdev, num = class_summaries[i]\n",
    "                class_prob[class_name] *= self.gaussianProbability(data_point[i], mean, stdev)\n",
    "        return class_prob\n",
    "    \n",
    "    # Function to classify the class of the data point\n",
    "    def bayesClassify(self, data_point):\n",
    "        max_prob = 0.0\n",
    "        max_class = 0.0\n",
    "        class_prob = self.classProbability(data_point)\n",
    "        for classes in class_prob:\n",
    "            if class_prob[classes] > max_prob:\n",
    "                max_prob = class_prob[classes]\n",
    "                max_class = classes\n",
    "        return max_class\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = r\"C:\\Studying Documents\\Artificial intelligient\\Exercise\\Dataset\\Iris.csv\"\n",
    "    bayes_classifier = NaiveBayes(file_path)\n",
    "    flower_1 = bayes_classifier.bayesClassify([4.7, 3, 2, 2.5])\n",
    "    flower_2 = bayes_classifier.bayesClassify([5.9, 3, 5.1, 1.8])\n",
    "    print(\"The class of the 1st data point is\", str(flower_1))\n",
    "    print(\"The class of the 2nd data point is\", str(flower_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8861c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
